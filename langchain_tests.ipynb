{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4bdaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILDAR\\anaconda3\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 1 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 1 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', '__abstractmethods__', '__annotations__', '__call__', '__class__', '__class_getitem__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__orig_bases__', '__parameters__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__ror__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '__weakref__', '_abatch_with_config', '_abc_impl', '_acall', '_acall_with_config', '_areturn', '_atake_next_step', '_atransform_stream_with_config', '_batch_with_config', '_calculate_keys', '_call', '_call_with_config', '_chain_type', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_tool_return', '_get_value', '_init_private_attributes', '_is_protocol', '_iter', '_lc_kwargs', '_prepare_intermediate_steps', '_return', '_run_output_key', '_should_continue', '_take_next_step', '_transform_stream_with_config', '_validate_inputs', '_validate_outputs', 'abatch', 'acall', 'agent', 'ainvoke', 'apply', 'arun', 'astream', 'astream_log', 'atransform', 'batch', 'bind', 'callback_manager', 'callbacks', 'construct', 'copy', 'dict', 'early_stopping_method', 'from_agent_and_tools', 'from_orm', 'get_lc_namespace', 'handle_parsing_errors', 'input_keys', 'invoke', 'is_lc_serializable', 'iter', 'json', 'lc_attributes', 'lc_secrets', 'lookup_tool', 'map', 'max_execution_time', 'max_iterations', 'memory', 'metadata', 'output_keys', 'parse_file', 'parse_obj', 'parse_raw', 'prep_inputs', 'prep_outputs', 'raise_callback_manager_deprecation', 'return_intermediate_steps', 'run', 'save', 'save_agent', 'schema', 'schema_json', 'set_verbose', 'stream', 'tags', 'to_json', 'to_json_not_implemented', 'tools', 'transform', 'trim_intermediate_steps', 'update_forward_refs', 'validate', 'validate_return_direct_tool', 'validate_runnable_agent', 'validate_tools', 'verbose', 'with_config', 'with_fallbacks', 'with_retry']\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "# from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.agents.agent_toolkits import GmailToolkit\n",
    "from langchain.tools.gmail.utils import build_resource_service, get_gmail_credentials\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    llama_llm = CTransformers(model=\"TheBloke/Llama-2-7B-Chat-GGML\", model_file = 'llama-2-7b-chat.ggmlv3.q2_K.bin', callbacks=[StreamingStdOutCallbackHandler()])\n",
    "    chat_gpt_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k')\n",
    "\n",
    "\n",
    "    template = \"\"\"[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant.\n",
    "Your answer are brief and usually not more thatn 10 words long.\n",
    "Always answer as helpfully as possible, while being safe.\n",
    "Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.\n",
    "If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "{text}[/INST]\"\"\"\n",
    "\n",
    "    toolkit = GmailToolkit()\n",
    "\n",
    "    # Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "    # For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "    credentials = get_gmail_credentials(\n",
    "        token_file=\"token.json\",\n",
    "        scopes=[\"https://mail.google.com/\"],\n",
    "        client_secrets_file=\"credentials.json\",\n",
    "    )\n",
    "    api_resource = build_resource_service(credentials=credentials)\n",
    "    toolkit = GmailToolkit(api_resource=api_resource)\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "\n",
    "    # llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    # # text = input(\"Write question:\")\n",
    "    text = \"What is my conversation in my gmail with Lucy.Chan@fragomen.com is about?\"\n",
    "    # response = llm_chain.run(text)\n",
    "    agent = initialize_agent(\n",
    "        tools=toolkit.get_tools(),\n",
    "        llm=chat_gpt_llm,\n",
    "        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(dir(agent))\n",
    "    # chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "    # help(chain)\n",
    "    # agent.run(text)\n",
    "    #     prompt.format(text=text)\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26cc118a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\ncreate_gmail_draft: Use this tool to create a draft email with the provided message fields., args: {{{{\\'message\\': {{{{\\'title\\': \\'Message\\', \\'description\\': \\'The message to include in the draft.\\', \\'type\\': \\'string\\'}}}}, \\'to\\': {{{{\\'title\\': \\'To\\', \\'description\\': \\'The list of recipients.\\', \\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}, \\'subject\\': {{{{\\'title\\': \\'Subject\\', \\'description\\': \\'The subject of the message.\\', \\'type\\': \\'string\\'}}}}, \\'cc\\': {{{{\\'title\\': \\'Cc\\', \\'description\\': \\'The list of CC recipients.\\', \\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}, \\'bcc\\': {{{{\\'title\\': \\'Bcc\\', \\'description\\': \\'The list of BCC recipients.\\', \\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}}}}}\\nsend_gmail_message: Use this tool to send email messages. The input is the message, recipients, args: {{{{\\'message\\': {{{{\\'title\\': \\'Message\\', \\'type\\': \\'string\\'}}}}, \\'to\\': {{{{\\'title\\': \\'To\\', \\'anyOf\\': [{{{{\\'type\\': \\'string\\'}}}}, {{{{\\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}]}}}}, \\'subject\\': {{{{\\'title\\': \\'Subject\\', \\'type\\': \\'string\\'}}}}, \\'cc\\': {{{{\\'title\\': \\'Cc\\', \\'anyOf\\': [{{{{\\'type\\': \\'string\\'}}}}, {{{{\\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}]}}}}, \\'bcc\\': {{{{\\'title\\': \\'Bcc\\', \\'anyOf\\': [{{{{\\'type\\': \\'string\\'}}}}, {{{{\\'type\\': \\'array\\', \\'items\\': {{{{\\'type\\': \\'string\\'}}}}}}}}]}}}}}}}}\\nsearch_gmail: Use this tool to search for email messages or threads. The input must be a valid Gmail query. The output is a JSON list of the requested resource., args: {{{{\\'query\\': {{{{\\'title\\': \\'Query\\', \\'description\\': \\'The Gmail query. Example filters include from:sender, to:recipient, subject:subject, -filtered_term, in:folder, is:important|read|starred, after:year/mo/date, before:year/mo/date, label:label_name \"exact phrase\". Search newer/older than using d (day), m (month), and y (year): newer_than:2d, older_than:1y. Attachments with extension example: filename:pdf. Multiple term matching example: from:amy OR from:david.\\', \\'type\\': \\'string\\'}}}}, \\'resource\\': {{{{\\'description\\': \\'Whether to search for threads or messages.\\', \\'default\\': \\'messages\\', \\'allOf\\': [{{{{\\'$ref\\': \\'#/definitions/Resource\\'}}}}]}}}}, \\'max_results\\': {{{{\\'title\\': \\'Max Results\\', \\'description\\': \\'The maximum number of results to return.\\', \\'default\\': 10, \\'type\\': \\'integer\\'}}}}}}}}\\nget_gmail_message: Use this tool to fetch an email by message ID. Returns the thread ID, snippet, body, subject, and sender., args: {{{{\\'message_id\\': {{{{\\'title\\': \\'Message Id\\', \\'description\\': \\'The unique ID of the email message, retrieved from a search.\\', \\'type\\': \\'string\\'}}}}}}}}\\nget_gmail_thread: Use this tool to search for email messages. The input must be a valid Gmail query. The output is a JSON list of messages., args: {{{{\\'thread_id\\': {{{{\\'title\\': \\'Thread Id\\', \\'description\\': \\'The thread ID.\\', \\'type\\': \\'string\\'}}}}}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or create_gmail_draft, send_gmail_message, search_gmail, get_gmail_message, get_gmail_thread\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.llm_chain.prompt.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45926d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_template'], output_parser=None, partial_variables={}, template='Summarize this LLM prompt with tools to fit to 768 context size. Keep tools by Large Lnaguage Model with smaller context size.\\n{agent_template}\\nSummarized Context:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"Summarize this LLM prompt with tools to fit to 768 context size. Keep tools by Large Lnaguage Model with smaller context size.\n",
    "{agent_template}\n",
    "Summarized Context:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1776c9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The LLM prompt is asking for a summary of a given LLM (Master of Laws) prompt. The summary should be concise and fit within a context size of 768 characters. The prompt also provides access to several tools that can be used to create a draft email, send email messages, search for email messages or threads, fetch an email by message ID, and search for email messages by thread ID. These tools can be used to assist in answering the prompt.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run chain\n",
    "# reduce_chain = LLMChain(llm=chat_gpt_llm, prompt=reduce_prompt)\n",
    "reduce_chain.run(agent_template = agent.agent.llm_chain.prompt.messages[0].prompt.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
